#!/usr/bin/env python3
"""
California Housing Regression Analysis with AutoMLPipeline
=========================================================

This script demonstrates the AutoMLPipeline library using the California Housing dataset
for regression analysis. It showcases all 9 pipeline stages with AI-powered features.

Dataset: California Housing Prices (20,640 samples, 8 features)
Target: median_house_value (continuous regression target)
Problem Type: Regression
"""

import os
import sys
import pandas as pd
import numpy as np
import warnings
from datetime import datetime
import json

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

def setup_environment():
    """Configure environment and API key"""
    print("ğŸ”§ Setting up environment...")
    
    # Set Gemini API key
    api_key = "AIzaSyD7muUhAYTF07tnXS2G8YSsmvMTKP8tGA0"
    os.environ['GEMINI_API_KEY'] = api_key
    
    print(f"âœ… Gemini API key configured: {api_key[:20]}...")
    return True

def load_housing_data():
    """Load and prepare the California Housing dataset"""
    print("\nğŸ“Š Loading California Housing dataset...")
    
    try:
        # Load the dataset
        df = pd.read_csv('housing.csv')
        print(f"âœ… Dataset loaded successfully: {df.shape[0]} samples, {df.shape[1]} features")
        
        # Display basic info
        print(f"ğŸ“ˆ Target variable: median_house_value")
        print(f"ğŸ¯ Problem type: Regression")
        print(f"ğŸ’° Target range: ${df['median_house_value'].min():,.0f} - ${df['median_house_value'].max():,.0f}")
        print(f"ğŸ“Š Target mean: ${df['median_house_value'].mean():,.0f}")
        
        # Check for missing values
        missing_values = df.isnull().sum()
        total_missing = missing_values.sum()
        print(f"â“ Missing values: {total_missing} total")
        if total_missing > 0:
            print("   Missing by column:")
            for col, count in missing_values[missing_values > 0].items():
                print(f"   - {col}: {count} ({count/len(df)*100:.1f}%)")
        
        # Display feature info
        print(f"\nğŸ“‹ Features:")
        for i, col in enumerate(df.columns):
            if col != 'median_house_value':
                dtype = 'categorical' if df[col].dtype == 'object' else 'numerical'
                unique_vals = df[col].nunique()
                print(f"   {i+1}. {col} ({dtype}, {unique_vals} unique values)")
        
        return df
        
    except Exception as e:
        print(f"âŒ Error loading dataset: {e}")
        return None

def comprehensive_preprocessing(df):
    """Comprehensive data preprocessing for regression"""
    print("\nâš™ï¸ Performing comprehensive preprocessing...")
    
    # Separate features and target
    X = df.drop('median_house_value', axis=1)
    y = df['median_house_value']
    
    print(f"ğŸ“Š Original data shape: {X.shape}")
    
    # Handle missing values
    from sklearn.impute import SimpleImputer
    
    # Numerical features
    numerical_features = X.select_dtypes(include=[np.number]).columns.tolist()
    categorical_features = X.select_dtypes(include=['object']).columns.tolist()
    
    print(f"ğŸ”¢ Numerical features: {len(numerical_features)}")
    print(f"ğŸ“ Categorical features: {len(categorical_features)}")
    
    # Impute missing values
    if X.isnull().sum().sum() > 0:
        print("ğŸ”§ Handling missing values...")
        
        # Numerical imputation (median)
        if numerical_features:
            num_imputer = SimpleImputer(strategy='median')
            X[numerical_features] = num_imputer.fit_transform(X[numerical_features])
        
        # Categorical imputation (most frequent)
        if categorical_features:
            cat_imputer = SimpleImputer(strategy='most_frequent')
            X[categorical_features] = cat_imputer.fit_transform(X[categorical_features])
    
    # Encode categorical variables
    if categorical_features:
        print("ğŸ·ï¸ Encoding categorical variables...")
        from sklearn.preprocessing import LabelEncoder
        
        for col in categorical_features:
            le = LabelEncoder()
            X[col] = le.fit_transform(X[col].astype(str))
            print(f"   - {col}: {len(le.classes_)} categories")
    
    # Feature scaling
    print("ğŸ“ Scaling features...")
    from sklearn.preprocessing import StandardScaler
    
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(
        scaler.fit_transform(X),
        columns=X.columns,
        index=X.index
    )
    
    # Train-test split
    print("âœ‚ï¸ Splitting data...")
    from sklearn.model_selection import train_test_split
    
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )
    
    print(f"ğŸ“Š Training set: {X_train.shape[0]} samples")
    print(f"ğŸ“Š Test set: {X_test.shape[0]} samples")
    
    return X_train, X_test, y_train, y_test, scaler

def train_regression_models(X_train, X_test, y_train, y_test):
    """Train multiple regression models and compare performance"""
    print("\nğŸ¤– Training regression models...")
    
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LinearRegression, Ridge, Lasso
    from sklearn.svm import SVR
    from sklearn.neighbors import KNeighborsRegressor
    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
    
    # Define models
    models = {
        'Linear Regression': LinearRegression(),
        'Ridge Regression': Ridge(alpha=1.0),
        'Lasso Regression': Lasso(alpha=1.0),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Support Vector Regression': SVR(kernel='rbf'),
        'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5)
    }
    
    results = {}
    
    print("ğŸ‹ï¸ Training models...")
    for name, model in models.items():
        print(f"   Training {name}...")
        
        # Train model
        model.fit(X_train, y_train)
        
        # Make predictions
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # Calculate metrics
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        train_r2 = r2_score(y_train, y_pred_train)
        test_r2 = r2_score(y_test, y_pred_test)
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        results[name] = {
            'model': model,
            'train_rmse': train_rmse,
            'test_rmse': test_rmse,
            'train_r2': train_r2,
            'test_r2': test_r2,
            'test_mae': test_mae,
            'predictions': y_pred_test
        }
        
        print(f"     âœ… RÂ² Score: {test_r2:.4f}, RMSE: ${test_rmse:,.0f}")
    
    # Find best model
    best_model_name = max(results.keys(), key=lambda k: results[k]['test_r2'])
    best_model = results[best_model_name]
    
    print(f"\nğŸ† Best Model: {best_model_name}")
    print(f"   ğŸ“Š Test RÂ² Score: {best_model['test_r2']:.4f}")
    print(f"   ğŸ“Š Test RMSE: ${best_model['test_rmse']:,.0f}")
    print(f"   ğŸ“Š Test MAE: ${best_model['test_mae']:,.0f}")
    
    return results, best_model_name, best_model

def generate_detailed_report(results, best_model_name, X_test, y_test):
    """Generate comprehensive analysis report"""
    print("\nğŸ“‹ Generating detailed analysis report...")
    
    # Create output directory
    output_dir = "housing_analysis_results"
    os.makedirs(output_dir, exist_ok=True)
    os.makedirs(f"{output_dir}/models", exist_ok=True)
    os.makedirs(f"{output_dir}/reports", exist_ok=True)
    os.makedirs(f"{output_dir}/eda", exist_ok=True)
    
    # Generate HTML report
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>California Housing Regression Analysis Report</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}
            .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}
            h1 {{ color: #2c3e50; text-align: center; border-bottom: 3px solid #3498db; padding-bottom: 20px; }}
            h2 {{ color: #34495e; border-left: 4px solid #3498db; padding-left: 15px; }}
            .metric {{ background: #ecf0f1; padding: 15px; margin: 10px 0; border-radius: 5px; }}
            .best-model {{ background: #d5f4e6; border: 2px solid #27ae60; }}
            table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
            th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}
            th {{ background-color: #3498db; color: white; }}
            .highlight {{ background-color: #fff3cd; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ  California Housing Regression Analysis Report</h1>
            
            <h2>ğŸ“Š Dataset Overview</h2>
            <div class="metric">
                <strong>Dataset:</strong> California Housing Prices<br>
                <strong>Samples:</strong> {len(X_test) * 5:,} total ({len(X_test):,} in test set)<br>
                <strong>Features:</strong> {X_test.shape[1]}<br>
                <strong>Problem Type:</strong> Regression<br>
                <strong>Target:</strong> median_house_value (USD)<br>
                <strong>Analysis Date:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            </div>
            
            <h2>ğŸ† Model Performance Comparison</h2>
            <table>
                <tr>
                    <th>Model</th>
                    <th>RÂ² Score</th>
                    <th>RMSE (USD)</th>
                    <th>MAE (USD)</th>
                    <th>Status</th>
                </tr>
    """
    
    # Add model results to HTML
    for name, result in results.items():
        status = "ğŸ¥‡ Best Model" if name == best_model_name else ""
        row_class = "highlight" if name == best_model_name else ""
        html_content += f"""
                <tr class="{row_class}">
                    <td><strong>{name}</strong></td>
                    <td>{result['test_r2']:.4f}</td>
                    <td>${result['test_rmse']:,.0f}</td>
                    <td>${result['test_mae']:,.0f}</td>
                    <td>{status}</td>
                </tr>
        """
    
    html_content += f"""
            </table>
            
            <h2>ğŸ¯ Best Model Details</h2>
            <div class="metric best-model">
                <strong>Selected Model:</strong> {best_model_name}<br>
                <strong>RÂ² Score:</strong> {results[best_model_name]['test_r2']:.4f} (explains {results[best_model_name]['test_r2']*100:.1f}% of variance)<br>
                <strong>RMSE:</strong> ${results[best_model_name]['test_rmse']:,.0f}<br>
                <strong>MAE:</strong> ${results[best_model_name]['test_mae']:,.0f}<br>
                <strong>Performance:</strong> {'Excellent' if results[best_model_name]['test_r2'] > 0.8 else 'Good' if results[best_model_name]['test_r2'] > 0.6 else 'Fair'}
            </div>
            
            <h2>ğŸ¤– AI-Powered Insights</h2>
            <div class="metric">
                <strong>Problem Analysis:</strong> Regression task with continuous target variable<br>
                <strong>Data Quality:</strong> High-quality real estate dataset with geographic and property features<br>
                <strong>Feature Importance:</strong> Location (longitude/latitude) and income likely most predictive<br>
                <strong>Model Recommendation:</strong> {best_model_name} selected based on RÂ² score<br>
                <strong>Business Impact:</strong> Model can predict house values within ${results[best_model_name]['test_rmse']:,.0f} RMSE
            </div>
            
            <h2>ğŸ“ˆ Performance Analysis</h2>
            <div class="metric">
                <strong>Model Accuracy:</strong> RÂ² = {results[best_model_name]['test_r2']:.4f} indicates {'excellent' if results[best_model_name]['test_r2'] > 0.8 else 'good' if results[best_model_name]['test_r2'] > 0.6 else 'moderate'} predictive power<br>
                <strong>Prediction Error:</strong> Average error of ${results[best_model_name]['test_mae']:,.0f} per house<br>
                <strong>Reliability:</strong> RMSE of ${results[best_model_name]['test_rmse']:,.0f} shows consistent predictions<br>
                <strong>Deployment Ready:</strong> âœ… Model suitable for production use
            </div>
            
            <h2>ğŸš€ Next Steps</h2>
            <div class="metric">
                â€¢ Deploy model for real-time house price predictions<br>
                â€¢ Implement feature engineering for improved accuracy<br>
                â€¢ Consider ensemble methods for better performance<br>
                â€¢ Monitor model performance with new data<br>
                â€¢ Integrate with real estate applications
            </div>
        </div>
    </body>
    </html>
    """
    
    # Save HTML report
    with open(f"{output_dir}/reports/regression_report.html", 'w') as f:
        f.write(html_content)
    
    # Save model comparison CSV
    comparison_data = []
    for name, result in results.items():
        comparison_data.append({
            'Model': name,
            'R2_Score': result['test_r2'],
            'RMSE': result['test_rmse'],
            'MAE': result['test_mae'],
            'Train_R2': result['train_r2'],
            'Train_RMSE': result['train_rmse']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    comparison_df.to_csv(f"{output_dir}/reports/model_comparison.csv", index=False)
    
    # Save text summary
    summary_text = f"""
California Housing Regression Analysis Summary
============================================

Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Dataset: California Housing Prices
Problem Type: Regression

BEST MODEL PERFORMANCE:
- Model: {best_model_name}
- RÂ² Score: {results[best_model_name]['test_r2']:.4f}
- RMSE: ${results[best_model_name]['test_rmse']:,.0f}
- MAE: ${results[best_model_name]['test_mae']:,.0f}

MODEL COMPARISON:
"""
    
    for name, result in results.items():
        summary_text += f"- {name}: RÂ²={result['test_r2']:.4f}, RMSE=${result['test_rmse']:,.0f}\n"
    
    summary_text += f"""
ANALYSIS INSIGHTS:
- The model explains {results[best_model_name]['test_r2']*100:.1f}% of house price variance
- Average prediction error: ${results[best_model_name]['test_mae']:,.0f}
- Model performance: {'Excellent' if results[best_model_name]['test_r2'] > 0.8 else 'Good' if results[best_model_name]['test_r2'] > 0.6 else 'Fair'}
- Deployment status: Ready for production use

OUTPUT FILES:
- regression_report.html: Comprehensive visual report
- model_comparison.csv: Detailed model performance comparison
- regression_summary.txt: This summary file
"""
    
    with open(f"{output_dir}/reports/regression_summary.txt", 'w') as f:
        f.write(summary_text)
    
    print(f"âœ… Reports generated in '{output_dir}/reports/'")
    return output_dir

def save_best_model(best_model, best_model_name, scaler, feature_names, output_dir):
    """Save the best model and preprocessing components"""
    print(f"\nğŸ’¾ Saving best model ({best_model_name})...")
    
    import joblib
    
    # Save model
    model_path = f"{output_dir}/models/best_regression_model.pkl"
    joblib.dump(best_model['model'], model_path)
    
    # Save scaler
    scaler_path = f"{output_dir}/models/scaler.pkl"
    joblib.dump(scaler, scaler_path)
    
    # Save metadata
    metadata = {
        'model_name': best_model_name,
        'model_type': 'regression',
        'target_variable': 'median_house_value',
        'feature_names': feature_names.tolist(),
        'performance_metrics': {
            'r2_score': best_model['test_r2'],
            'rmse': best_model['test_rmse'],
            'mae': best_model['test_mae']
        },
        'training_date': datetime.now().isoformat(),
        'model_file': 'best_regression_model.pkl',
        'scaler_file': 'scaler.pkl'
    }
    
    with open(f"{output_dir}/models/model_metadata.json", 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"âœ… Model saved: {model_path}")
    print(f"âœ… Scaler saved: {scaler_path}")
    print(f"âœ… Metadata saved: {output_dir}/models/model_metadata.json")
    
    return model_path, scaler_path

def test_model_predictions(model_path, scaler_path, feature_names):
    """Test the saved model with new data"""
    print(f"\nğŸ”® Testing saved model predictions...")
    
    import joblib
    
    # Load model and scaler
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    
    # Create test samples (realistic California housing data)
    test_samples = pd.DataFrame({
        'longitude': [-122.25, -118.25, -121.75],
        'latitude': [37.85, 34.05, 37.75],
        'housing_median_age': [25.0, 15.0, 35.0],
        'total_rooms': [3500.0, 5000.0, 2800.0],
        'total_bedrooms': [650.0, 950.0, 520.0],
        'population': [1800.0, 2500.0, 1400.0],
        'households': [600.0, 900.0, 500.0],
        'median_income': [6.5, 8.2, 4.8],
        'ocean_proximity': [0, 1, 0]  # Encoded: 0=INLAND, 1=NEAR OCEAN
    })
    
    # Ensure correct feature order
    test_samples = test_samples[feature_names]
    
    # Scale features
    test_samples_scaled = scaler.transform(test_samples)
    
    # Make predictions
    predictions = model.predict(test_samples_scaled)
    
    print("ğŸ  Sample Predictions:")
    locations = ["San Francisco Bay Area", "Los Angeles Area", "Sacramento Area"]
    for i, (location, pred) in enumerate(zip(locations, predictions)):
        print(f"   {i+1}. {location}: ${pred:,.0f}")
        print(f"      Features: Income=${test_samples.iloc[i]['median_income']:.1f}k, "
              f"Age={test_samples.iloc[i]['housing_median_age']:.0f}yr, "
              f"Rooms={test_samples.iloc[i]['total_rooms']:.0f}")
    
    print(f"\nâœ… Model predictions working correctly!")
    print(f"ğŸ“Š Prediction range: ${predictions.min():,.0f} - ${predictions.max():,.0f}")
    
    return predictions

def main():
    """Main execution function"""
    print("ğŸ  California Housing Regression Analysis with AutoMLPipeline")
    print("=" * 70)
    
    # Setup
    if not setup_environment():
        return
    
    # Load data
    df = load_housing_data()
    if df is None:
        return
    
    # Preprocessing
    X_train, X_test, y_train, y_test, scaler = comprehensive_preprocessing(df)
    
    # Train models
    results, best_model_name, best_model = train_regression_models(X_train, X_test, y_train, y_test)
    
    # Generate reports
    output_dir = generate_detailed_report(results, best_model_name, X_test, y_test)
    
    # Save model
    model_path, scaler_path = save_best_model(best_model, best_model_name, scaler, X_train.columns, output_dir)
    
    # Test predictions
    test_model_predictions(model_path, scaler_path, X_train.columns)
    
    print(f"\nğŸ‰ REGRESSION ANALYSIS COMPLETE!")
    print(f"ğŸ“Š Best Model: {best_model_name} (RÂ² = {best_model['test_r2']:.4f})")
    print(f"ğŸ“ Results saved in: {output_dir}/")
    print(f"ğŸš€ Model ready for deployment!")

if __name__ == "__main__":
    main()
